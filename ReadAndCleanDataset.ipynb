{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac06a1-5880-4966-949b-1b2e4273014d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f0f2d3d-3c53-4785-9f44-374f4a84a074",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Read and Clean Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "66820768-0921-4f1b-8abf-9c44f56a9753",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908f6e9a-f1b8-41b8-96b7-931f9ff91060",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read and clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1828cc87-5d9e-4818-8ef9-6471740da2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2019 = pd.read_csv('2019_RAW_APC_Data.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b267519-5264-4f2a-8ff2-ba723f2a0b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['route finish time','route start time','stop arrival time']:\n",
    "    data2019[col] = pd.to_datetime(data2019[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35ef5685-6a8c-4b15-9e92-dee31cf5e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data2019\n",
    "\n",
    "df['Crowded'] = df['passwithin']>74\n",
    "df['Supercrowded'] = df['passwithin']>134\n",
    "df['Capacity'] = df['passwithin']>194\n",
    "df['UnderNeg5'] = df['passwithin']<-5\n",
    "df['NegAFew'] = df['passwithin'].between(-5,-1)\n",
    "df['Over250'] = df['passwithin']>250\n",
    "df['AllObservations'] = True\n",
    "\n",
    "df['Crowded000'] = df['passwithin']>0\n",
    "df['Crowded010'] = df['passwithin']>10\n",
    "df['Crowded020'] = df['passwithin']>20\n",
    "df['Crowded030'] = df['passwithin']>30\n",
    "df['Crowded040'] = df['passwithin']>40\n",
    "df['Crowded050'] = df['passwithin']>50\n",
    "df['Crowded060'] = df['passwithin']>60\n",
    "df['Crowded070'] = df['passwithin']>70\n",
    "df['Crowded080'] = df['passwithin']>80\n",
    "df['Crowded090'] = df['passwithin']>90\n",
    "df['Crowded100'] = df['passwithin']>100\n",
    "df['Crowded110'] = df['passwithin']>110\n",
    "df['Crowded120'] = df['passwithin']>120\n",
    "df['Crowded130'] = df['passwithin']>130\n",
    "df['Crowded140'] = df['passwithin']>140\n",
    "df['Crowded150'] = df['passwithin']>150\n",
    "df['Crowded160'] = df['passwithin']>160\n",
    "df['Crowded170'] = df['passwithin']>170\n",
    "df['Crowded180'] = df['passwithin']>180\n",
    "df['Crowded190'] = df['passwithin']>190\n",
    "df['Crowded200'] = df['passwithin']>200\n",
    "df['Crowded210'] = df['passwithin']>210\n",
    "df['Crowded220'] = df['passwithin']>220\n",
    "df['Crowded230'] = df['passwithin']>230\n",
    "df['Crowded240'] = df['passwithin']>240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9b26180-d410-40f1-92a4-276ab3da3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data2019\n",
    "\n",
    "df['TOD'] = df['stop arrival time'].dt.time\n",
    "df['DOW'] = df['stop arrival time'].dt.dayofweek # 0 is Monday, 6 is Sunday\n",
    "df['DOW_name'] = df['stop arrival time'].dt.day_name()\n",
    "df['Date'] = df['stop arrival time'].dt.date\n",
    "df['Hour'] = df['stop arrival time'].dt.hour\n",
    "df['Minute'] = df['stop arrival time'].dt.minute\n",
    "df['Minute_od'] = df['Hour'] * 60 + df['Minute']\n",
    "df['Month'] = df['stop arrival time'].dt.month\n",
    "df['Month_name'] = df['stop arrival time'].dt.month_name()\n",
    "df['Season'] = df['stop arrival time'].dt.quarter\n",
    "df['DOY'] = df['stop arrival time'].dt.dayofyear\n",
    "df['WOY'] = df['stop arrival time'].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c0583dc-5f3b-45a9-9f25-96762b378699",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data2019\n",
    "\n",
    "# Create a station ID\n",
    "# Use a dictionary\n",
    "names = ['Zero','Angle','SeaTac','Tukwila','Rainier','Othello',\n",
    "         'Columbia','Baker','Beacon','SODO','Stadium','Intl District',\n",
    "         'Pioneer','University','Westlake','Capitol Hill ','UW ']\n",
    "\n",
    "for idx, name in enumerate(names):\n",
    "    df.loc[df['station name']==name, 'sta_ID'] = idx\n",
    "    df.loc[df['next station']==name, 'nxsta_ID'] = idx\n",
    "    \n",
    "df['sta_ID'] = df['sta_ID'].astype('int32')\n",
    "df['nxsta_ID'] = df['nxsta_ID'].astype('int32')\n",
    "df['stadir_ID'] = df['sta_ID'] * 100 + df['nxsta_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2aea71d-63e9-4737-aff6-56b362591004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df01 filters out routedones that have >20 stops\n",
    "rtd = data2019.groupby('routedone').count()['railcar ID']\n",
    "rtd.name = 'count'\n",
    "overmuch = rtd[rtd>20]\n",
    "df01 = data2019[~data2019['routedone'].isin(overmuch.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "426c3216-9eab-4c28-a08a-6cf04ad9c8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df02 is df01 but without >210 observations\n",
    "df02 = df01[~df01['Crowded210']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1df28174-527f-4f2d-b946-f5b64b5f5c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df03 is df02 but without any against-equation trips\n",
    "\n",
    "against_calc = pd.read_csv('routes_against_calc.csv').iloc[:,0]\n",
    "\n",
    "df03 = df02[~df02['routedone'].isin(against_calc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6809c6f-ad9f-4fb5-8ccf-4582993dce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df04 is df03 but without any trips where the train visited stations out of sequence.\n",
    "# In other words, df04 consists of only normal stadir values.\n",
    "\n",
    "abnormal = pd.read_csv('abnormal_stadir_routes.csv').iloc[:,0]\n",
    "\n",
    "df04 = df03[~df03['routedone'].isin(abnormal)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
